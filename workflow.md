
1. Dockerfileを作成してイメージ作成
2. docker build
3. docker run
4. docker logs
5. ソースコード修正に対応するための方法 バインドマウント
6. composeを使っての作業
7. イメージ配布 & タグ付け
8. CIとテスト


## tips
- バインドマウント時にしている`-v`のパスは相対パスではなく絶対パスにする必要がある
- 言語ごとのバージョン管理ツールvirtualenvやrubyenv等のツールはdockerではそれほど有効なツールではなくなるので導入が不要 理由はコンテナ内で複数の言語バージョンを使う必要が無いから
- dockerfileにユーザ追加と実行ユーザの指定をしないとデフォルトでrootユーザが全てを実行することになる のでdockerfileではUSER文を必ず設定すること
- コンテナ群を扱う場合はdocker-composeを使用すると管理が楽になる
- タグ付けは`docker build -t identidock:0.1 .`のように:タグで指定する
- タグ付けのルールは大文字小文字、数字、.-、128文字まで使える タグの命名規則をチームで考えることは大事
- latestタグは最新版を意味するので使い勝手が良さそうだが、各ローカルにlatestタグを持つイメージがあってリポジトリに最新のlatestタグが指定されているイメージが存在していてもローカルにlatestが存在するのでdockerはリモートからイメージを取得しようとしない
- イメージを公開する最も単純なソリューションはdocker hubに自分のイメージをpushすること dockerはデフォルトのレジストリにdocker hubが使われているのでdocker loginしていればすぐにpushすることが出来る ただデフォルトだとpublicリポジトリなので見られたくないイメージの場合は課金してからprivateリポジトリにpushする
- docker hubには自動ビルドのオプションが用意されていて、githubのリポジトリに指定ブランチのコードがpushされたらそれをトリガーにdocker hubでイメージをビルドしてくれる
- プライベートリポジトリを自分で設定したい場合はdocker registryを使ってレジストリを立てるとよい
- イメージサイズの削減 デプロイ時にdockerイメージのサイズが大きいとそれだけ時間がかかってしまう のでdockerイメージのレイヤを考えながらdockerfileを作成する
- イメージサイズの削減方法 1つのRUN内でダウンロード -> 展開 -> ダウンロードしたtarなどは展開後に削除 この方法を取ることによって展開するtarのサイズを使わずに済む ポイントは1つのRUN内で行うこと
- テスト用のコンテナを作ってテスト毎にコンテナを生成する方法もある 使用するイメージは1つだがコンテナは実行毎に分ける
- jenkinsでテストした後は自動ビルドを行う jenkinsのビルドスクリプトにテスト結果に応じてdockerレジストリにイメージをpushするか記述する
- jenkinsサーバーのdockerイメージは定期的に削除する必要がある
- docker運用(マイクロサービス)をするにあたってテストは重要になる
- テストの種類 ユニットテスト, コンポーネントテスト, エンドトゥエンドテスト, 結合テスト
- nginx等のconfファイルはDockerfile内でcopyする
- docker-machineを使用するとリモートサーバー上でイメージをビルドしたり出来る
- ポート公開はproxyサーバーのみにすると安全
- runにはリスタートオプションを設定することが出来る alwaysはリスタートを何度も実行する on-failureは0以外の終了コードで終了したコンテナだけを再起動するポリシーでリトライの回数も設定することが出来る
- ansible等の設定ファイルを使用する場合はコンテナ内部を管理するのではなく、dockerホストを管理するようにする
- dockerホストの選択は、中小規模のアプリケーションなら使い慣れたOS(Ubuntu, Fedra)で十分、大規模ではdockerに特化したCoreOS, Project AtomicなどのOSを使用しましょう、クラウドを使用する場合はdocker用のイメージが用意されているのでそれを使用しましょう
- ホスティングサービスの選択肢 Trition, Google Container Engineなど
- 秘密情報の取扱い イメージ内に秘密情報を保存してしまうのは絶対にダメ 有効な手法として環境変数に秘密情報を保持してコンテナはその秘密情報を読み込む(ただ筆者は推奨していない) ボリュームに秘密情報を保存しておく方法もある 現時点で最も安全なソリューションはKVSに秘密鍵を保存しておきそれを読み込んで使用する方法 どちらにせよKVSにアクセスするための秘密情報が必要ではある
- 素のままのDockerのネットワークを使用しているということはパフォーマンスの影響をかなり受けているということになる
- デフォルトのdockerでのロギングはSTDOUTやSTRERRに送られた内容を全てロギングする docker logsコマンドで確認することが出来る STDOUT, STDERRしかロギングしないということはファイルにしかログを出せないアプリケーションのログはデフォルトの方法では取得できないということになる
- docker run時に--log-driver=を選択することが出来る
- ログの集約方法1 全てのコンテナでエージェントを起動しログを集約サービスにフォワードする ただしこの方法ではイメージサイズが肥大化する欠点がある
- ログの集約方法2 ホスト上または独立したスタンドアローンコンテナにログを集約し集約サービスにフォワードする
- ロギングの選択肢の中にELKスタックがある、Elasticsearch, Logstash, Kibana + Logspout LogspoutでLogstashにデータを流しLogstashがパースしたログをElasticsearchに流しそれをKibanaで可視化する
- ロギングでホストやスタンドアローンコンテナにログを集約してもストレージとローテーションのことも頭に入れておかないとマシンをクラッシュさせてしまう logrotateユーティリティを使えばログファイルの増大を管理することが出来る
- rsyslogを使うとLogspoutを置き換えることが出来る
- ログの保証 rsyslogには@@か@でトランスポートプロトコルを選択することが出来る TCPを使いたいなら@@, UDPを使いたいなら@を設定する TCPの方が信頼性が高い UDPは高速だがTCP程は信頼性が保証できない
- cAdvisor GoogleのContainerAdvisorはDockerモニタリングツール
- クラスタ用のモニタリングソリューションとしてPrometheusがある




